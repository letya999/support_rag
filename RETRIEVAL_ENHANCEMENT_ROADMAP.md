# Support RAG - Retrieval Enhancement Roadmap

**Comprehensive implementation plan for Phases 3-4 of the Support RAG pipeline.**

---

## ðŸ“Š Current Status

### âœ… Phases 1-2: COMPLETE
- Retrieval metrics: Hit Rate, MRR, Exact Match
- Generation metrics: Faithfulness, Relevancy
- Benchmarking framework with multiple scripts
- Full Langfuse integration
- LangGraph pipeline: retrieve â†’ route â†’ generate

---

## ðŸŽ¯ PHASE 3: Intent-Based Retrieval Optimization (~4 days)

### 3.1 Classification Node (Zero-shot BERT)
**Without training. No dependencies.**

**What:** Classify user questions into intents and categories at the start of pipeline.

**Intents:** faq, complaint, suggestion, technical, billing, account
**Categories:** billing, shipping, account, product, returns, technical, general

**How:**
- Use `facebook/bart-large-mnli` zero-shot classification (HuggingFace transformers)
- Async classification for both intent + category in parallel
- Simple LRU cache for repeated questions
- Singleton service pattern

**Files to create:**
```
app/nodes/classification/
  â”œâ”€â”€ prompts.py        (define intents/categories)
  â”œâ”€â”€ classifier.py     (ClassificationService with zero-shot logic)
  â”œâ”€â”€ models.py         (ClassificationOutput Pydantic model)
  â””â”€â”€ node.py          (LangGraph node wrapper)
```

**Integration:**
- Update `app/pipeline/state.py` â†’ add: intent, intent_confidence, category, category_confidence
- Update `app/pipeline/graph.py` â†’ add classify_node as START node
- Update `requirements.txt` â†’ add: transformers>=4.30.0, torch>=2.0.0

**Benefits:**
- âœ… Fast (~100-200ms, no API calls)
- âœ… Free
- âœ… Deterministic (same input = same output)
- âœ… Enables category-aware retrieval

---

### 3.2 Metadata Filtering Node (with Safety Fallback)
**Smart filtering with safety mechanisms.**

**What:** Filter documents by classified category to improve precision.

**Safety Logic:**
```
if category_confidence < 0.5:
    skip filtering â†’ search all documents
elif retrieve(category) returns >= 2 docs:
    use filtered results
else:
    FALLBACK to full search (log warning)
```

**How:**
- Update `app/storage/vector_store.py` â†’ add optional `category_filter` parameter
- Add SQL WHERE clause: `metadata->>'category' = %s`
- Create filtering service with fallback logic
- Log all filtering decisions for monitoring

**Files to create:**
```
app/nodes/metadata_filtering/
  â”œâ”€â”€ filtering.py      (MetadataFilteringService with fallback)
  â”œâ”€â”€ models.py         (FilteringOutput with stats)
  â””â”€â”€ node.py          (LangGraph node wrapper)
```

**Integration:**
- Update `app/pipeline/state.py` â†’ add: filter_used, fallback_triggered, filtering_reason
- Update `app/pipeline/graph.py` â†’ add metadata_filter_node between classify and retrieve
- Update `app/storage/vector_store.py` â†’ category_filter parameter support

**Benefits:**
- âœ… Higher precision (filter by category)
- âœ… Safety first (fallback if needed)
- âœ… Observable (log all decisions)

---

### 3.3 Improve Routing Logic
**Multi-metric decision making.**

**Current:** `if confidence >= threshold â†’ auto_reply else â†’ handoff` (binary)

**New:** 3-way routing based on multiple confidence scores
```
if generation_confidence > 0.85 and faithfulness > 0.8:
    â†’ auto_reply
elif generation_confidence > 0.5:
    â†’ needs_review
else:
    â†’ escalation
```

**How:**
- Compute `generation_confidence = avg(faithfulness_score, relevancy_score)` in route_node
- Factor in `fallback_triggered` (be cautious if filter had to fallback)
- Store all scores in state for logging/debugging

**Files to update:**
```
app/nodes/routing/
  â”œâ”€â”€ logic.py         (update decide_action signature)
  â””â”€â”€ node.py         (compute generation_confidence)
```

**Integration:**
- Update `app/pipeline/state.py` â†’ add: generation_confidence, faithfulness_score, relevancy_score
- Update `app/api/routes.py` â†’ return all scores in `/ask` response JSON
- Update routing to handle 3+ outcomes

**Benefits:**
- âœ… Better routing (uses multiple metrics)
- âœ… Transparent (can see all scores)
- âœ… Safer (accounts for fallback flag)

---

## ðŸŽ¯ PHASE 4: Advanced Retrieval Nodes (~5-7 days optional)

### Strategy: Rule-Based + LLM Hybrid

Choose one of these options:

---

### Option A: Production-Ready with Rule-Based (~5-6 days) â­ RECOMMENDED

**Fast, cheap, optimized for domain.**

#### 4.1 Slang Normalizer (0.5 day)
- Transform product-specific slang into standard terms
- Example: "pipe" â†’ "pipeline", "rejectable" â†’ "rejected records"
- Implementation: Simple dictionary + word-level replacement
- File: `app/nodes/slang_normalizer/normalizer.py`

#### 4.2 Spelling Correction (0.5 day)
- Fix typos before search (use pyspellchecker or autocorrect library)
- Example: "configer" â†’ "configure"
- Implementation: Pre-trained library + domain terms
- File: `app/nodes/spelling_correction/corrector.py`

#### 4.3 Synonym Expansion (1 day)
- Expand question with domain-specific synonyms
- Example: "return" â†’ ["refund", "send back", "money back"]
- Implementation: YAML dictionary + keyword matching
- File: `app/nodes/synonym_expansion/expander.py`

#### 4.4 Rule-Based Reformulation (2 days)
- Regex pattern-based query reformulation (no LLM!)
- Example: "error: 404" â†’ add "troubleshooting", "debug", "fix"
- Implementation: Regex patterns + action engine
- File: `app/nodes/rule_reformulation/engine.py`

#### 4.5 Intent-Aware Synonyms (1 day)
- Use different synonyms per intent/category
- Example: "order" (billing) vs "order" (shipping) â†’ different synonyms
- Implementation: Intent-keyed dictionary
- File: `app/nodes/intent_synonyms/mapper.py`

**Integration order:**
```
classify â†’ slang_normalizer â†’ spelling_correction â†’
intent_aware_synonyms â†’ synonym_expansion â†’
rule_reformulation â†’ metadata_filter â†’ retrieve
```

**Result:** Fast, deterministic, fully customizable for your domain.

---

### Option B: Full-Featured (~7-9 days)

**Everything from Option A + advanced LLM + reasoning.**

Add to Option A:

#### 4.6 LLM Query Reformulation (1-2 days)
- Generate 2-3 reformulations using gpt-4o-mini
- Learns patterns from your domain
- Implementation: LangChain LLM + prompt template
- File: `app/nodes/llm_reformulation/reformulator.py`

#### 4.7 Multi-Hop Reasoning (2-3 days)
- For complex questions, find chains of related documents
- Detect complexity â†’ retrieve top-1 â†’ find related â†’ combine
- Implementation: Complexity scorer + hop resolver
- Files: `app/nodes/multihop/complexity_detector.py`, `hop_resolver.py`

#### 4.8 Cross-Reference Resolution (1 day)
- Find documents linked via metadata.see_also
- Example: FAQ links to "Return Policy" â†’ retrieve both
- Implementation: Link parser + batch retrieval
- File: `app/nodes/cross_reference/resolver.py`

#### 4.9 Semantic Clustering (1 day)
- Group similar documents together
- Reduces redundancy, better context organization
- Implementation: Embedding similarity + clustering
- File: `app/nodes/clustering/clusterer.py`

**Result:** Handles complex questions, but slower and more expensive.

---

## ðŸ“Š Comparison

| | Option A (Rule-Based) | Option B (Full) |
|---|---|---|
| **Speed** | âš¡ Fast (no API calls) | Slower (LLM calls) |
| **Cost** | Free | ðŸ’° Per request |
| **Setup Time** | 5-6 days | 7-9 days |
| **Customization** | Easy (just rules) | Medium (rules + prompts) |
| **Best For** | Domain-specific support | General + complex Q&A |
| **Maintenance** | Simple | More complex |

---

## ðŸ”„ Final Pipeline Architecture

### After Phase 3 (Required):
```
START â†’ classify â†’ metadata_filter â†’ retrieve â†’
route â†’ [generate or END]
```

### After Phase 4 (Optional):
```
START â†’ slang_normalizer â†’ spelling_correction â†’
classify â†’ intent_synonyms â†’ synonym_expansion â†’
rule_reformulation â†’ metadata_filter â†’ retrieve â†’
[rerank â†’ clustering â†’ cross_reference â†’ multihop] â†’
merge_context â†’ generate â†’ route â†’ END
```

---

## ðŸ“ Implementation Summary

### Phase 3 Files to Create:
```
app/nodes/classification/
  â”œâ”€â”€ __init__.py
  â”œâ”€â”€ prompts.py
  â”œâ”€â”€ classifier.py
  â”œâ”€â”€ models.py
  â””â”€â”€ node.py

app/nodes/metadata_filtering/
  â”œâ”€â”€ __init__.py
  â”œâ”€â”€ filtering.py
  â”œâ”€â”€ models.py
  â””â”€â”€ node.py
```

### Phase 3 Files to Update:
```
app/pipeline/state.py        (add new fields)
app/pipeline/graph.py        (integrate new nodes)
app/nodes/routing/logic.py   (multi-metric routing)
app/nodes/routing/node.py    (compute scores)
app/storage/vector_store.py  (category filter)
app/api/routes.py            (enhanced responses)
requirements.txt             (transformers, torch)
```

### Phase 4 Files to Create (if chosen):
```
Option A (5 files):
- app/nodes/slang_normalizer/
- app/nodes/spelling_correction/
- app/nodes/synonym_expansion/
- app/nodes/rule_reformulation/
- app/nodes/intent_synonyms/

Option B (9 files):
- All from Option A +
- app/nodes/llm_reformulation/
- app/nodes/multihop/
- app/nodes/cross_reference/
- app/nodes/clustering/
```

---

## â±ï¸ Timeline

```
Phase 3 (Required): 4 days
  - 3.1 Classification: 1-2 days
  - 3.2 Filtering: 1-2 days
  - 3.3 Routing: 0.5 day
  - Integration + testing: 0.5 day

Phase 4 (Optional):
  - Option A: 5-6 days
  - Option B: 7-9 days
  - Selective (pick 2-3 nodes): 2-3 days

Total: Phase 3 (4 days) + Phase 4 A (5-6 days) = 9-10 days for MVP
```

---

## âœ… Success Metrics

### Phase 3 Success:
- âœ… Classification accuracy: >90% on test set
- âœ… Fallback rate: <30% (filter working)
- âœ… Routing: 3-way decisions logged
- âœ… All scores returned in API

### Phase 4A Success (Rule-Based):
- âœ… No external API calls (fast)
- âœ… Deterministic results
- âœ… Easy to debug and customize
- âœ… ~30-40% improvement in recall

### Phase 4B Success (Full):
- âœ… Handles complex questions (multi-hop)
- âœ… Better query understanding
- âœ… ~50-60% improvement in recall
- âœ… Production-ready

---

## ðŸŽ¯ Recommendation

**Start with:** Phase 3 (4 days) + Option A (5-6 days) = **9-10 days total**

This gives you:
- âœ… Production-ready support RAG
- âœ… Fast and cheap (no LLM calls for retrieval)
- âœ… Domain-optimized
- âœ… Easy to customize

Then optionally add LLM features (4.6, 4.7) if you see value.

---

## ðŸ“š Testing & Documentation

Each phase should include:
- Unit tests for each node
- Integration tests for full pipeline
- Test scripts for validation
- Documentation/README for each node
- Example configurations

---

## ðŸš€ Next Steps

1. Choose Phase 3 (required) or skip to Phase 4
2. Choose Phase 4 option (A, B, or selective)
3. Create feature branch for implementation
4. Implement nodes in recommended order
5. Test and validate with ground truth dataset
6. Create PR with comprehensive changes
