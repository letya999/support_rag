# üöÄ Pipeline Optimization Roadmap

> **–î–æ–∫—É–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω:** 2026-01-05  
> **–í–µ—Ä—Å–∏—è:** 1.0  
> **–°—Ç–∞—Ç—É—Å:** –í —Ä–∞–±–æ—Ç–µ  
> **–û–±—â–µ–µ –≤—Ä–µ–º—è pipeline (—Ç–µ–∫—É—â–µ–µ):** ~12 —Å–µ–∫—É–Ω–¥  
> **–¶–µ–ª–µ–≤–æ–µ –≤—Ä–µ–º—è:** < 2 —Å–µ–∫—É–Ω–¥

---

## üìä –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (Trace Analysis)

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ | –¶–µ–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ |
|---------|-----------------|------------------|
| –û–±—â–µ–µ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ | 12.1 —Å–µ–∫ | < 2 —Å–µ–∫ |
| `hybrid_search` | 8.1 —Å–µ–∫ (67%) | < 500 –º—Å |
| `generation` (LLM) | 3.2 —Å–µ–∫ | 2-3 —Å–µ–∫ (–Ω–æ—Ä–º–∞) |
| Rerank best score | 0.0024 | > 0.5 |
| Classification confidence | 0.55 | > 0.8 |
| Cache hit rate | 0% | > 40% |

---

## üéØ –§–∞–∑–∞ 1: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–¶–µ–ª—å:** –°–Ω–∏–∑–∏—Ç—å –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ —Å 12 –¥–æ 3-4 —Å–µ–∫—É–Ω–¥  
**–°—Ä–æ–∫:** 2-3 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π

---

### –ó–∞–¥–∞—á–∞ 1.1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Qdrant Client (Singleton + Async)

**–ü—Ä–æ–±–ª–µ–º–∞:**  
Vector search –∑–∞–Ω–∏–º–∞–µ—Ç 8 —Å–µ–∫—É–Ω–¥. –ö–ª–∏–µ–Ω—Ç Qdrant —Å–æ–∑–¥–∞—ë—Ç—Å—è –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å, –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç connection pooling.

**–†–µ—à–µ–Ω–∏–µ:**  
–ü–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ Qdrant: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `AsyncQdrantClient` –∫–∞–∫ singleton —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º `pool_size`.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/integrations/qdrant/qdrant_client.py

from qdrant_client import AsyncQdrantClient
from functools import lru_cache

_client: AsyncQdrantClient | None = None

async def get_qdrant_client() -> AsyncQdrantClient:
    global _client
    if _client is None:
        _client = AsyncQdrantClient(
            url=settings.qdrant_url,
            prefer_grpc=True,  # gRPC –±—ã—Å—Ç—Ä–µ–µ REST
            grpc_options={
                "grpc.max_receive_message_length": 50 * 1024 * 1024,
            }
        )
    return _client
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/integrations/qdrant/qdrant_client.py`
- `app/nodes/hybrid_search/node.py`
- `app/nodes/retrieval/node.py`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Qdrant client —Å–æ–∑–¥–∞—ë—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- [ ] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è gRPC –≤–º–µ—Å—Ç–æ REST API
- [ ] Connection reuse –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –≤ –ª–æ–≥–∞—Ö
- [ ] Vector search –≤—Ä–µ–º—è < 200ms (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤ trace)

---

### –ó–∞–¥–∞—á–∞ 1.2: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ (Vector + Lexical)

**–ü—Ä–æ–±–ª–µ–º–∞:**  
Vector search –∏ Lexical search –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è **–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ**, —Ö–æ—Ç—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞.

**–†–µ—à–µ–Ω–∏–µ:**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `asyncio.gather()` –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/hybrid_search/node.py

async def execute(self, state: PipelineState) -> dict:
    query = state.get("aggregated_query") or state["question"]
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫
    vector_task = self._vector_search(query, state.get("matched_category"))
    lexical_task = self._lexical_search(query)
    
    vector_results, lexical_results = await asyncio.gather(
        vector_task,
        lexical_task,
        return_exceptions=True
    )
    
    # Fusion —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    return self._fuse_results(vector_results, lexical_results)
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Vector –∏ Lexical search –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- [ ] –û–±—â–µ–µ –≤—Ä–µ–º—è hybrid_search = max(vector, lexical) –∞ –Ω–µ sum
- [ ] Hybrid search –≤—Ä–µ–º—è < 500ms
- [ ] Graceful degradation –ø—Ä–∏ –æ—à–∏–±–∫–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –ø–æ–∏—Å–∫–æ–≤

---

### –ó–∞–¥–∞—á–∞ 1.3: PostgreSQL Full-Text Search Optimization

**–ü—Ä–æ–±–ª–µ–º–∞:**  
Lexical search –∑–∞–Ω–∏–º–∞–µ—Ç 8 —Å–µ–∫—É–Ω–¥. –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç GIN –∏–Ω–¥–µ–∫—Å –Ω–∞ `tsvector`.

**–†–µ—à–µ–Ω–∏–µ:**  
–ü–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ PostgreSQL: –¥–æ–±–∞–≤–∏—Ç—å stored `tsvector` column —Å GIN –∏–Ω–¥–µ–∫—Å–æ–º.

**SQL –º–∏–≥—Ä–∞—Ü–∏—è:**
```sql
-- migrations/007_add_tsvector_index.sql

-- 1. –î–æ–±–∞–≤–∏—Ç—å stored tsvector column
ALTER TABLE qa_documents 
ADD COLUMN search_vector tsvector 
GENERATED ALWAYS AS (
    setweight(to_tsvector('russian', coalesce(question, '')), 'A') ||
    setweight(to_tsvector('russian', coalesce(answer, '')), 'B') ||
    setweight(to_tsvector('english', coalesce(question, '')), 'A') ||
    setweight(to_tsvector('english', coalesce(answer, '')), 'B')
) STORED;

-- 2. –°–æ–∑–¥–∞—Ç—å GIN –∏–Ω–¥–µ–∫—Å
CREATE INDEX idx_qa_search_vector ON qa_documents USING GIN(search_vector);

-- 3. –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –Ω–∞ category –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
CREATE INDEX idx_qa_category ON qa_documents((metadata->>'category'));

-- 4. Analyze –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ query planner
ANALYZE qa_documents;
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/db/migrations/007_add_tsvector_index.sql` (–Ω–æ–≤—ã–π)
- `app/nodes/lexical_search/lexical_search_db.py`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] GIN –∏–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (–ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ EXPLAIN ANALYZE)
- [ ] Lexical search –≤—Ä–µ–º—è < 50ms
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤
- [ ] –†–∞–±–æ—Ç–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ category

---

### –ó–∞–¥–∞—á–∞ 1.4: PostgreSQL Connection Pooling

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL.

**–†–µ—à–µ–Ω–∏–µ:**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `asyncpg` pool —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/db/connection.py

import asyncpg
from contextlib import asynccontextmanager

_pool: asyncpg.Pool | None = None

async def init_db_pool():
    global _pool
    _pool = await asyncpg.create_pool(
        dsn=settings.database_url,
        min_size=5,
        max_size=20,
        command_timeout=5.0,  # 5 —Å–µ–∫—É–Ω–¥ —Ç–∞–π–º–∞—É—Ç
        statement_cache_size=100,  # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ prepared statements
    )

@asynccontextmanager
async def get_connection():
    async with _pool.acquire() as conn:
        yield conn
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/db/connection.py`
- `app/main.py` (lifespan)
- `app/nodes/lexical_search/lexical_search_db.py`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Connection pool —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- [ ] Pool size: min=5, max=20
- [ ] Statement caching –≤–∫–ª—é—á—ë–Ω
- [ ] –ù–µ—Ç "connection refused" –æ—à–∏–±–æ–∫ –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π

---

## üéØ –§–∞–∑–∞ 2: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ ML-–º–æ–¥–µ–ª–µ–π

**–¶–µ–ª—å:** –ü–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ reranking  
**–°—Ä–æ–∫:** 3-4 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† –í—ã—Å–æ–∫–∏–π

---

### –ó–∞–¥–∞—á–∞ 2.1: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è BGE Reranker

**–ü—Ä–æ–±–ª–µ–º–∞:**  
Rerank scores –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–µ (0.0024). –ú–æ–¥–µ–ª—å `BAAI/bge-reranker-v2-m3` –ø–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ "Question: ... Answer: ...", –∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–ª—É—á–∞—Ç—å —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.

**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è BGE:**
- –û–∂–∏–¥–∞–µ—Ç –ø–∞—Ä—ã `(query, passage)` –≥–¥–µ passage ‚Äî plain text
- –ú–∞–∫—Å–∏–º—É–º 512 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –ø–∞—Ä—É
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç relevance score ‚Üí sigmoid ‚Üí [0, 1]

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/nodes/reranking/ranker.py

def _prepare_pairs(self, query: str, docs: list[str]) -> list[tuple[str, str]]:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø–∞—Ä—ã –¥–ª—è reranker –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    pairs = []
    for doc in docs:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç, —É–±–∏—Ä–∞–µ–º Question/Answer —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        clean_doc = self._extract_answer(doc)
        pairs.append((query, clean_doc))
    return pairs

def _extract_answer(self, doc: str) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    if "Answer:" in doc:
        return doc.split("Answer:", 1)[1].strip()
    return doc

async def rerank(self, query: str, docs: list[str]) -> list[tuple[str, float]]:
    pairs = self._prepare_pairs(query, docs)
    
    # Batch inference –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    inputs = self.tokenizer(
        pairs,
        padding=True,
        truncation=True,
        max_length=512,
        return_tensors="pt"
    )
    
    with torch.no_grad():
        scores = self.model(**inputs).logits.squeeze(-1)
        scores = torch.sigmoid(scores).tolist()
    
    return sorted(zip(docs, scores), key=lambda x: -x[1])
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/nodes/reranking/ranker.py`
- `app/services/reranker/reranker.py`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Rerank scores > 0.5 –¥–ª—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- [ ] Input format: `(query, clean_answer)` –±–µ–∑ "Question:" prefix
- [ ] Batch processing —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ 512 —Ç–æ–∫–µ–Ω–∞–º–∏

---

### –ó–∞–¥–∞—á–∞ 2.2: –î–æ–±–∞–≤–∏—Ç—å "query:" prefix –¥–ª—è E5 embeddings

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–ú–æ–¥–µ–ª—å `intfloat/multilingual-e5-small` —Ç—Ä–µ–±—É–µ—Ç prefix "query: " –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤, –∏–Ω–∞—á–µ –∫–∞—á–µ—Å—Ç–≤–æ embeddings —Å—Ç—Ä–∞–¥–∞–µ—Ç.

**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è E5:**
> For classification/clustering/semantic similarity, prepend "query: " to input texts.

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/integrations/embeddings/get_embedding.py

def get_embedding(text: str, is_query: bool = True) -> list[float]:
    """
    –ü–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞.
    
    Args:
        text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
        is_query: True –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, False –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    if is_query:
        text = f"query: {text}"
    else:
        text = f"passage: {text}"
    
    return model.encode(text, normalize_embeddings=True).tolist()
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/integrations/embeddings/get_embedding.py`
- `app/nodes/hybrid_search/node.py`
- `app/nodes/retrieval/node.py`
- `scripts/index_documents.py` (–¥–ª—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏)

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] –ó–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–º–µ—é—Ç prefix "query: "
- [ ] –î–æ–∫—É–º–µ–Ω—Ç—ã –≤ Qdrant –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã —Å prefix "passage: "
- [ ] Vector search precision —É–ª—É—á—à–∏–ª—Å—è (A/B —Ç–µ—Å—Ç)
- [ ] Embeddings –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã

---

### –ó–∞–¥–∞—á–∞ 2.3: –£–ª—É—á—à–µ–Ω–∏–µ Dialog Analysis (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ is_question)

**–ü—Ä–æ–±–ª–µ–º–∞:**  
`is_question: false` –¥–ª—è —è–≤–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ "tell about your shipping opportunities".

**–†–µ—à–µ–Ω–∏–µ:**  
–î–æ–±–∞–≤–∏—Ç—å ML-based question detection –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å rule-based –ª–æ–≥–∏–∫—É.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/dialog_analysis/rules/question_detector.py

QUESTION_PATTERNS = [
    r'\?$',                          # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ ?
    r'^(what|how|why|when|where|who|which|can|do|does|is|are|will|would|could)\b',
    r'^(–∫–∞–∫|–ø–æ—á–µ–º—É|–∫–æ–≥–¥–∞|–≥–¥–µ|–∫—Ç–æ|–∫–∞–∫–æ–π|–º–æ–∂–Ω–æ|–ª–∏)\b',
    r'\b(tell me|explain|describe|show|help)\b',
    r'\b(—Ä–∞—Å—Å–∫–∞–∂–∏|–æ–±—ä—è—Å–Ω–∏|–ø–æ–∫–∞–∂–∏|–ø–æ–º–æ–≥–∏)\b',
    r'\b(about|–ø—Ä–æ|–æ|–æ–±)\b.*\??\s*$',  # –í–æ–ø—Ä–æ—Å –æ —á—ë–º-—Ç–æ
]

def is_question(text: str) -> bool:
    text_lower = text.lower().strip()
    
    for pattern in QUESTION_PATTERNS:
        if re.search(pattern, text_lower, re.IGNORECASE):
            return True
    
    return False
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/nodes/dialog_analysis/rules/question_detector.py` (–Ω–æ–≤—ã–π)
- `app/nodes/dialog_analysis/node.py`
- `app/nodes/dialog_analysis/config.yaml`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] "Tell me about X" –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ –≤–æ–ø—Ä–æ—Å
- [ ] "Pls tell about X" –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ –≤–æ–ø—Ä–æ—Å
- [ ] –í–æ–ø—Ä–æ—Å—ã —Å "?" –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤
- [ ] Unit tests –ø–æ–∫—Ä—ã–≤–∞—é—Ç edge cases

---

## üéØ –§–∞–∑–∞ 3: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è State Management

**–¶–µ–ª—å:** –£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä state –∏ –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è  
**–°—Ä–æ–∫:** 2-3 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –°—Ä–µ–¥–Ω–∏–π

---

### –ó–∞–¥–∞—á–∞ 3.1: Reducers –¥–ª—è State

**–ü—Ä–æ–±–ª–µ–º–∞:**  
State —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
- `docs` –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –∏–∑ 3 nodes
- `matched_category` –∏ `semantic_category` ‚Äî –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ
- –í—Å—è –∏—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ

**–†–µ—à–µ–Ω–∏–µ:**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LangGraph reducers –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/pipeline/state.py

from typing import Annotated
from langgraph.graph import add_messages

def keep_latest(existing: list | None, new: list | None) -> list:
    """Reducer: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é."""
    return new if new is not None else existing

def merge_unique(existing: list | None, new: list | None) -> list:
    """Reducer: –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."""
    if existing is None:
        return new or []
    if new is None:
        return existing
    seen = set()
    result = []
    for item in existing + new:
        key = item if isinstance(item, str) else str(item)
        if key not in seen:
            seen.add(key)
            result.append(item)
    return result

class PipelineState(TypedDict):
    question: str
    user_id: str
    session_id: str
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º reducers
    docs: Annotated[list[str], keep_latest]
    conversation_history: Annotated[list[dict], add_messages]
    
    # –£–Ω–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    category: str  # –í–º–µ—Å—Ç–æ matched_category + semantic_category
    
    # Confidence —Ç–µ–ø–µ—Ä—å –æ–¥–∏–Ω
    confidence: float  # –í–º–µ—Å—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ä–∞–∑–Ω—ã—Ö confidence
```

**–§–∞–π–ª—ã –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è:**
- `app/pipeline/state.py`
- –í—Å–µ nodes –∫–æ—Ç–æ—Ä—ã–µ –æ–±–Ω–æ–≤–ª—è—é—Ç state

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] State size —É–º–µ–Ω—å—à–∏–ª—Å—è –Ω–∞ 40%+
- [ ] –ù–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è docs –º–µ–∂–¥—É nodes
- [ ] –ï–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è category/intent
- [ ] Reducers –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç None

---

### –ó–∞–¥–∞—á–∞ 3.2: Lazy Loading –¥–ª—è User Profile –∏ Session History

**–ü—Ä–æ–±–ª–µ–º–∞:**  
User profile –∏ session history –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –≤—Å–µ–≥–¥–∞, –¥–∞–∂–µ –∫–æ–≥–¥–∞ –Ω–µ –Ω—É–∂–Ω—ã.

**–†–µ—à–µ–Ω–∏–µ:**  
–ó–∞–≥—Ä—É–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (–¥–ª—è prompt_routing –∏ generation).

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/session_starter/node.py

async def execute(self, state: PipelineState) -> dict:
    result = {}
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º user_profile —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
    if self.params.get("load_user_profile", True):
        result["user_profile"] = await self._load_user_profile(state["user_id"])
    
    # Session history –∑–∞–≥—Ä—É–∂–∞–µ–º lazy
    result["_session_history_loader"] = lambda: self._load_session_history(
        state["session_id"]
    )
    
    return result
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Session history –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ prompt_routing
- [ ] User profile –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–µ–Ω
- [ ] –û–±—â–µ–µ –≤—Ä–µ–º—è session_starter < 30ms

---

### –ó–∞–¥–∞—á–∞ 3.3: Trimming Conversation History

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–í conversation_history –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è (4+ —Å–æ–æ–±—â–µ–Ω–∏–π), —á—Ç–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç tokens –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å.

**–†–µ—à–µ–Ω–∏–µ:**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `trim_messages` –∏ summarization.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/prompt_routing/node.py

from langchain_core.messages import trim_messages

def _prepare_history(self, history: list[dict], max_tokens: int = 500) -> str:
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å trimming."""
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ LangChain messages
    messages = [
        HumanMessage(content=m["content"]) if m["role"] == "user"
        else AIMessage(content=m["content"])
        for m in history
    ]
    
    # Trim –¥–æ max_tokens
    trimmed = trim_messages(
        messages,
        max_tokens=max_tokens,
        strategy="last",  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ
        token_counter=self._count_tokens,
        include_system=False
    )
    
    return self._format_messages(trimmed)
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Conversation history –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ 500 —Ç–æ–∫–µ–Ω–∞–º–∏
- [ ] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è strategy="last" –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- [ ] Summarization –¥–ª—è —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

---

## üéØ –§–∞–∑–∞ 4: Language Detection –∏ Localization

**–¶–µ–ª—å:** –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è  
**–°—Ä–æ–∫:** 1-2 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü° –°—Ä–µ–¥–Ω–∏–π

---

### –ó–∞–¥–∞—á–∞ 4.1: Language Detection Node

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, —Å–∏—Å—Ç–µ–º–∞ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º.

**–†–µ—à–µ–Ω–∏–µ:**  
–î–æ–±–∞–≤–∏—Ç—å language detection –∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —è–∑—ã–∫ –≤ generation.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/language_detection/node.py

from langdetect import detect, detect_langs

class LanguageDetectionNode(BaseNode):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    
    async def execute(self, state: PipelineState) -> dict:
        question = state["question"]
        
        try:
            detected = detect_langs(question)
            primary_lang = detected[0]
            
            return {
                "detected_language": primary_lang.lang,
                "language_confidence": round(primary_lang.prob, 2)
            }
        except:
            return {
                "detected_language": "ru",  # fallback
                "language_confidence": 0.5
            }
```

**–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ generation:**
```python
# app/nodes/generation/node.py

def _build_system_prompt(self, state: PipelineState) -> str:
    lang = state.get("detected_language", "ru")
    
    if lang == "en":
        return "You are a helpful support assistant. Answer clearly and concisely."
    else:
        return "–¢—ã - —ç–º–ø–∞—Ç–∏—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –û—Ç–≤–µ—á–∞–π —á–µ—Ç–∫–æ –∏ –∫—Ä–∞—Ç–∫–æ."
```

**–§–∞–π–ª—ã:**
- `app/nodes/language_detection/` (–Ω–æ–≤—ã–π node)
- `app/nodes/generation/node.py`
- `app/pipeline/graph.py`
- `app/pipeline/pipeline_order.yaml`

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã ‚Üí –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
- [ ] –†—É—Å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã ‚Üí —Ä—É—Å—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
- [ ] Language detection < 5ms
- [ ] Fallback –Ω–∞ —Ä—É—Å—Å–∫–∏–π –ø—Ä–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–º —è–∑—ã–∫–µ

---

## üéØ –§–∞–∑–∞ 5: Caching –∏ Warm-up

**–¶–µ–ª—å:** –£–≤–µ–ª–∏—á–∏—Ç—å cache hit rate –¥–æ 40%+  
**–°—Ä–æ–∫:** 2 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü¢ –ù–æ—Ä–º–∞–ª—å–Ω—ã–π

---

### –ó–∞–¥–∞—á–∞ 5.1: Semantic Cache

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–¢–µ–∫—É—â–∏–π cache key: `"hi opportunities pls shipping tell your"` ‚Äî –ø—Ä–æ—Å—Ç–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è. –ü–æ—Ö–æ–∂–∏–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ cache.

**–†–µ—à–µ–Ω–∏–µ:**  
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å semantic similarity –¥–ª—è cache lookup.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/nodes/check_cache/semantic_cache.py

class SemanticCache:
    def __init__(self, similarity_threshold: float = 0.92):
        self.threshold = similarity_threshold
        self.embedding_model = get_embedding_model()
    
    async def get(self, query: str) -> dict | None:
        query_embedding = self.embedding_model.encode(f"query: {query}")
        
        # –ü–æ–∏—Å–∫ –≤ Redis —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º vector similarity
        cached_items = await self._get_recent_cache_items(limit=100)
        
        for item in cached_items:
            similarity = cosine_similarity(query_embedding, item["embedding"])
            if similarity >= self.threshold:
                return item["response"]
        
        return None
    
    async def set(self, query: str, response: dict, ttl: int = 86400):
        embedding = self.embedding_model.encode(f"query: {query}")
        await redis.set(
            f"cache:{hash(query)}",
            {
                "query": query,
                "embedding": embedding.tolist(),
                "response": response,
            },
            ex=ttl
        )
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Semantic similarity threshold = 0.92
- [ ] Cache hit –¥–ª—è –ø–∞—Ä–∞—Ñ—Ä–∞–∑–æ–≤ ("How can I track package?" ‚âà "Track my order")
- [ ] Cache hit rate > 40% –Ω–∞ production traffic
- [ ] TTL = 24 —á–∞—Å–∞

---

### –ó–∞–¥–∞—á–∞ 5.2: Model Warm-up –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –º–µ–¥–ª–µ–Ω–Ω—ã–π –∏–∑-–∑–∞ lazy loading –º–æ–¥–µ–ª–µ–π.

**–†–µ—à–µ–Ω–∏–µ:**  
Warm-up –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ lifespan.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
```python
# app/main.py

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("üî• Warming up models...")
    
    # Parallel warmup
    await asyncio.gather(
        warm_up_embedding_model(),
        warm_up_reranker_model(),
        warm_up_classification_model(),
        init_qdrant_client(),
        init_db_pool(),
    )
    
    logger.info("‚úÖ All models warmed up")
    yield
    
    # Cleanup
    await close_qdrant_client()
    await close_db_pool()
```

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
- [ ] –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–µ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö
- [ ] Startup time < 30 —Å–µ–∫—É–Ω–¥
- [ ] Graceful shutdown

---

## üéØ –§–∞–∑–∞ 6: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ Observability

**–¶–µ–ª—å:** –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ production  
**–°—Ä–æ–∫:** 1-2 –¥–Ω—è  
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü¢ –ù–æ—Ä–º–∞–ª—å–Ω—ã–π

---

### –ó–∞–¥–∞—á–∞ 6.1: –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–∞–∂–¥—ã–π node

**–†–µ—à–µ–Ω–∏–µ:**
```python
# app/nodes/base_node/node.py

import time
from prometheus_client import Histogram, Counter

NODE_LATENCY = Histogram(
    'pipeline_node_latency_seconds',
    'Node execution latency',
    ['node_name']
)

NODE_ERRORS = Counter(
    'pipeline_node_errors_total',
    'Node error count',
    ['node_name', 'error_type']
)

class BaseNode:
    async def __call__(self, state: PipelineState) -> dict:
        start = time.perf_counter()
        try:
            result = await self.execute(state)
            NODE_LATENCY.labels(node_name=self.name).observe(
                time.perf_counter() - start
            )
            return result
        except Exception as e:
            NODE_ERRORS.labels(
                node_name=self.name,
                error_type=type(e).__name__
            ).inc()
            raise
```

**–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞:**
- `pipeline_total_latency_p95` ‚Äî –æ–±—â–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
- `pipeline_node_latency_p95` –ø–æ –∫–∞–∂–¥–æ–º—É node
- `rerank_best_score` ‚Äî –∫–∞—á–µ—Å—Ç–≤–æ reranking
- `classification_confidence` ‚Äî —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- `cache_hit_rate` ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç cache hits
- `error_rate` ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Prometheus –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö nodes
- [ ] Grafana –¥–∞—à–±–æ—Ä–¥ —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
- [ ] Alerts –¥–ª—è P95 latency > 5 —Å–µ–∫
- [ ] Alerts –¥–ª—è error rate > 1%

---

## üìã –ß–µ–∫–ª–∏—Å—Ç –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –§–∞–∑–∞ 1 (–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è)
- [ ] 1.1 Qdrant singleton client
- [ ] 1.2 –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π hybrid search
- [ ] 1.3 PostgreSQL GIN index
- [ ] 1.4 PostgreSQL connection pool
- [ ] **Checkpoint:** –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ < 4 —Å–µ–∫

### –§–∞–∑–∞ 2 (ML Quality)
- [ ] 2.1 BGE Reranker input format
- [ ] 2.2 E5 "query:" prefix
- [ ] 2.3 Question detection
- [ ] **Checkpoint:** Rerank score > 0.5, Classification > 0.8

### –§–∞–∑–∞ 3 (State Management)
- [ ] 3.1 State reducers
- [ ] 3.2 Lazy loading
- [ ] 3.3 History trimming
- [ ] **Checkpoint:** State size -40%

### –§–∞–∑–∞ 4 (Localization)
- [ ] 4.1 Language detection
- [ ] **Checkpoint:** Correct language in 95% responses

### –§–∞–∑–∞ 5 (Caching)
- [ ] 5.1 Semantic cache
- [ ] 5.2 Model warm-up
- [ ] **Checkpoint:** Cache hit rate > 40%

### –§–∞–∑–∞ 6 (Monitoring)
- [ ] 6.1 Node metrics
- [ ] **Checkpoint:** Dashboards operational

---

## üìä –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ | –ü–æ—Å–ª–µ –§–∞–∑—ã 1 | –ü–æ—Å–ª–µ –≤—Å–µ—Ö —Ñ–∞–∑ |
|---------|-----|-------------|----------------|
| –û–±—â–µ–µ –≤—Ä–µ–º—è | 12.1s | < 4s | < 2s |
| Hybrid search | 8.1s | < 500ms | < 300ms |
| Rerank score | 0.002 | > 0.3 | > 0.5 |
| Classification | 0.55 | 0.75 | > 0.8 |
| Cache hits | 0% | 20% | > 40% |
| Correct language | 0% | 50% | 95% |

---

## üîó –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

- [Qdrant AsyncQdrantClient](https://qdrant.tech/documentation/sdk/python-async/)
- [Qdrant Performance Tuning](https://qdrant.tech/documentation/guides/optimization/)
- [PostgreSQL GIN Indexes](https://www.postgresql.org/docs/current/textsearch-indexes.html)
- [BGE Reranker v2-m3](https://huggingface.co/BAAI/bge-reranker-v2-m3)
- [E5 Multilingual Small](https://huggingface.co/intfloat/multilingual-e5-small)
- [LangGraph State Management](https://langchain-ai.github.io/langgraph/concepts/low_level/)
