# PHASE 3 ROADMAP - Intent-Based Retrieval Optimization

## ðŸŽ¯ Ð’Ð«Ð‘Ð ÐÐÐÐ«Ð™ ÐŸÐžÐ”Ð¥ÐžÐ”: Zero-shot BERT Classification

**ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Zero-shot BERT?**
- âœ… Ð Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð¸Ð· ÐºÐ¾Ñ€Ð¾Ð±ÐºÐ¸ (no training needed)
- âœ… ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð»Ñ intent/category ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
- âœ… Open source Ð¸ Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð¾
- âœ… Ð›ÐµÐ³ÐºÐ¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ intent/category
- âœ… Ð‘Ñ‹ÑÑ‚Ñ€Ð¾ (~100-200ms per question)
- âœ… Ð˜Ð´ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ MVP opensource

**Ð’Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ:** `facebook/bart-large-mnli` (Ñ‡ÐµÑ€ÐµÐ· HuggingFace transformers)

---

## ðŸ“‹ ÐŸÐžÐ›ÐÐ«Ð™ ROADMAP Ð¤ÐÐ—Ð« 3

### Ð—ÐÐ”ÐÐ§Ð 3.1: Classification Node (Zero-shot BERT)
**Ð’Ñ€ÐµÐ¼Ñ:** 2-3 Ð´Ð½Ñ | **ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚:** ðŸ”´ HIGH

#### 3.1.1 Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ð°
**Ð¤Ð°Ð¹Ð»Ñ‹:**
```
app/nodes/classification/
â”œâ”€â”€ __init__.py                    (empty or exports)
â”œâ”€â”€ node.py                        (LangGraph node wrapper)
â”œâ”€â”€ classifier.py                  (Zero-shot classifier logic)
â”œâ”€â”€ models.py                      (Pydantic models for I/O)
â””â”€â”€ prompts.py                     (Definition of intents/categories)
```

#### 3.1.2 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/classification/prompts.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
# ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð²ÑÐµÑ… Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ñ… Ð¸Ð½Ñ‚ÐµÐ½Ñ‚Ð¾Ð² Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹
INTENTS = [
    "faq",              # General question
    "complaint",        # User complaint
    "suggestion",       # User suggestion/feature request
    "billing",          # Billing related
    "technical",        # Technical issue
    "account",          # Account management
]

CATEGORIES = [
    "billing",          # Billing & payments
    "shipping",         # Shipping & delivery
    "account",          # Account & authentication
    "product",          # Product info
    "returns",          # Returns & refunds
    "technical",        # Technical support
    "general",          # General inquiry
]

# Hint phrases Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ (optional, for zero-shot)
INTENT_HINTS = {
    "faq": ["how to", "what is", "can i", "do you", "where is"],
    "complaint": ["bad", "wrong", "broken", "not working", "issue"],
    "suggestion": ["suggest", "feature", "idea", "improvement", "better"],
    # ... etc
}
```

#### 3.1.3 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/classification/classifier.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
- `ClassificationService` (singleton)
  - Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¾Ð´Ð¸Ð½ Ñ€Ð°Ð·: `facebook/bart-large-mnli`
  - ÐœÐµÑ‚Ð¾Ð´ `classify_intent(question)` â†’ (intent, confidence)
  - ÐœÐµÑ‚Ð¾Ð´ `classify_category(question)` â†’ (category, confidence)
  - ÐœÐµÑ‚Ð¾Ð´ `classify_both(question)` â†’ (intent, category, intent_conf, category_conf)
  - ÐšÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² (LRU cache Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ question hash)

**Ð›Ð¾Ð³Ð¸ÐºÐ°:**
```python
class ClassificationService:
    def __init__(self):
        self.pipe = pipeline(
            "zero-shot-classification",
            model="facebook/bart-large-mnli",
            device=0  # GPU if available
        )
        self.cache = {}  # Simple dict cache

    async def classify_intent(self, question: str):
        """Classify into intents"""
        result = self.pipe(
            question,
            INTENTS,
            multi_class=False  # Single label
        )
        return {
            "intent": result["labels"][0],
            "confidence": float(result["scores"][0])
        }

    async def classify_category(self, question: str):
        """Classify into categories"""
        result = self.pipe(
            question,
            CATEGORIES,
            multi_class=False
        )
        return {
            "category": result["labels"][0],
            "confidence": float(result["scores"][0])
        }

    async def classify_both(self, question: str):
        """Classify intent AND category"""
        intent_result = await self.classify_intent(question)
        category_result = await self.classify_category(question)
        return {
            "intent": intent_result["intent"],
            "intent_confidence": intent_result["confidence"],
            "category": category_result["category"],
            "category_confidence": category_result["confidence"],
            "all_category_scores": {
                cat: score
                for cat, score in zip(
                    category_result.get("labels", []),
                    category_result.get("scores", [])
                )
            }
        }
```

#### 3.1.4 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/classification/models.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
class ClassificationOutput(BaseModel):
    intent: str                               # faq, complaint, etc
    intent_confidence: float                  # 0.0-1.0
    category: str                             # billing, shipping, etc
    category_confidence: float                # 0.0-1.0
    all_category_scores: Dict[str, float]    # {category: score, ...}
```

#### 3.1.5 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/classification/node.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
@observe(as_type="span")
async def classify_node(state: Dict[str, Any]):
    """
    LangGraph node for intent & category classification
    """
    question = state.get("question", "")
    service = get_classification_service()  # Singleton

    result = await service.classify_both(question)

    return {
        "intent": result["intent"],
        "intent_confidence": result["intent_confidence"],
        "category": result["category"],
        "category_confidence": result["category_confidence"],
        "all_category_scores": result["all_category_scores"]
    }
```

#### 3.1.6 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/pipeline/state.py`
**Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ñ:**
```python
class State(TypedDict):
    # ... existing fields ...

    # NEW: Classification results
    intent: Optional[str]                    # faq, complaint, etc
    intent_confidence: Optional[float]       # 0.0-1.0
    category: Optional[str]                  # billing, shipping, etc
    category_confidence: Optional[float]     # 0.0-1.0
    all_category_scores: Optional[Dict[str, float]]  # All categories ranked
```

#### 3.1.7 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/pipeline/graph.py`
**Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð³Ñ€Ð°Ñ„:**
```python
from app.nodes.classification.node import classify_node

workflow = StateGraph(State)

# Add classification as FIRST node
workflow.add_node("classify", classify_node)
workflow.add_node("expand_query", expand_query_node)
workflow.add_node("retrieve", retrieve_node)
# ... rest of nodes ...

# Update edges
workflow.add_edge(START, "classify")
workflow.add_edge("classify", "expand_query")
# ... rest of edges ...
```

#### 3.1.8 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/config/settings.py`
**Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÑƒ:**
```python
class Settings(BaseSettings):
    # ... existing ...

    # Classification config
    INTENT_CONFIDENCE_THRESHOLD: float = 0.5  # Skip if lower
    CATEGORY_CONFIDENCE_THRESHOLD: float = 0.4  # Use fallback if lower
    USE_CLASSIFICATION: bool = True
```

#### 3.1.9 Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ `scripts/test_classification.py`
**Ð”Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:**
- Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ground truth dataset
- Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ question:
  - Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ classify_node
  - Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ Ñ expected intent/category (if available)
  - Ð’Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ accuracy, precision, recall
- Ð’Ñ‹Ð²ÐµÑÑ‚Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ (console + JSON report)

---

### Ð—ÐÐ”ÐÐ§Ð 3.2: Metadata Filtering Node (Ñ safety Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ð°Ð¼Ð¸)
**Ð’Ñ€ÐµÐ¼Ñ:** 2-3 Ð´Ð½Ñ | **ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚:** ðŸ”´ HIGH

#### 3.2.1 Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°
**Ð¤Ð°Ð¹Ð»Ñ‹:**
```
app/nodes/metadata_filtering/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ node.py                      (LangGraph node wrapper)
â”œâ”€â”€ filtering.py                 (Filtering logic with safety)
â””â”€â”€ models.py                    (Pydantic models)
```

#### 3.2.2 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/metadata_filtering/filtering.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
class MetadataFilteringService:
    def __init__(self, safety_threshold=0.5, min_results=2):
        self.safety_threshold = safety_threshold
        self.min_results = min_results

    async def filter_and_search(
        self,
        question: str,
        category: Optional[str],
        category_confidence: float,
        all_category_scores: Optional[Dict[str, float]] = None,
        top_k: int = 3
    ) -> FilteringOutput:
        """
        Smart filtering with safety mechanisms

        Logic:
        1. If category_confidence < safety_threshold â†’ skip filtering
        2. If retrieve from category AND found >= min_results â†’ use filtered
        3. If retrieve from category AND found < min_results â†’ FALLBACK to all
        4. Else â†’ return all documents
        """

        # Step 1: Check if we should use filtering at all
        if category_confidence < self.safety_threshold:
            # Low confidence - skip filter
            results = await retrieve_all(question, top_k)
            return FilteringOutput(
                docs=results,
                filter_used=False,
                fallback_triggered=False,
                reason="Low category confidence - no filtering"
            )

        # Step 2: Try to retrieve from category
        if category:
            results = await retrieve_by_category(question, category, top_k)

            if len(results) >= self.min_results:
                # Success - we have enough results
                return FilteringOutput(
                    docs=results,
                    filter_used=True,
                    fallback_triggered=False,
                    reason=f"Filtered by {category} - found {len(results)} docs"
                )
            else:
                # Not enough results - FALLBACK
                all_results = await retrieve_all(question, top_k)
                return FilteringOutput(
                    docs=all_results,
                    filter_used=True,
                    fallback_triggered=True,
                    reason=f"Filter fallback: {category} had only {len(results)} docs, using all"
                )

        # Step 3: No category - retrieve all
        results = await retrieve_all(question, top_k)
        return FilteringOutput(
            docs=results,
            filter_used=False,
            fallback_triggered=False,
            reason="No category - searching all documents"
        )

    async def retrieve_by_category(
        self,
        question: str,
        category: str,
        top_k: int
    ) -> List[Document]:
        """Retrieve documents for specific category"""
        embedding = await get_embedding(question)
        return await search_documents(
            embedding,
            category_filter=category,
            top_k=top_k
        )

    async def retrieve_all(
        self,
        question: str,
        top_k: int
    ) -> List[Document]:
        """Retrieve from all documents"""
        embedding = await get_embedding(question)
        return await search_documents(
            embedding,
            category_filter=None,
            top_k=top_k
        )
```

#### 3.2.3 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/metadata_filtering/models.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
class FilteringOutput(BaseModel):
    docs: List[Document]           # Retrieved documents
    filter_used: bool              # Was filtering applied?
    fallback_triggered: bool       # Did we fallback to full search?
    reason: str                    # Explanation for logging
    category_docs_count: int       # Documents in category (if used)
    total_docs_searched: int       # Total documents in database
```

#### 3.2.4 Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ `app/nodes/metadata_filtering/node.py`
**Ð¡Ð¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚:**
```python
@observe(as_type="span")
async def metadata_filter_node(state: Dict[str, Any]):
    """
    Metadata filtering node with safety mechanisms
    """
    question = state.get("question", "")
    category = state.get("category")
    category_confidence = state.get("category_confidence", 0.0)
    all_category_scores = state.get("all_category_scores", {})

    service = get_metadata_filtering_service()

    result = await service.filter_and_search(
        question=question,
        category=category,
        category_confidence=category_confidence,
        all_category_scores=all_category_scores,
        top_k=3
    )

    return {
        "docs": result.docs,
        "filter_used": result.filter_used,
        "fallback_triggered": result.fallback_triggered,
        "filtering_reason": result.reason
    }
```

#### 3.2.5 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/storage/vector_store.py`
**ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð¿Ð¾Ð¸ÑÐºÐ°:**
```python
async def search_documents(
    query_embedding: List[float],
    category_filter: Optional[str] = None,
    top_k: int = 3
) -> List[SearchResult]:
    """
    Search documents with optional category filtering
    """

    query = """
    SELECT content, 1 - (embedding <=> %s::vector) AS score, metadata
    FROM documents
    """

    params = [query_embedding]

    # Add category filter if provided
    if category_filter:
        query += "WHERE metadata->>'category' = %s"
        params.append(category_filter)

    query += "ORDER BY score DESC LIMIT %s"
    params.append(top_k)

    async with get_async_db_connection() as conn:
        rows = await conn.execute(query, params)

        return [
            SearchResult(
                content=row[0],
                score=float(row[1]),
                metadata=row[2] or {}
            )
            for row in rows
        ]
```

#### 3.2.6 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/pipeline/state.py`
**Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ñ:**
```python
class State(TypedDict):
    # ... existing fields ...

    # NEW: Filtering results
    filter_used: Optional[bool]
    fallback_triggered: Optional[bool]
    filtering_reason: Optional[str]
```

#### 3.2.7 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/pipeline/graph.py`
**Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ node Ð¸ edge:**
```python
from app.nodes.metadata_filtering.node import metadata_filter_node

workflow.add_node("metadata_filter", metadata_filter_node)

# After classification, before expand_query
workflow.add_edge("classify", "metadata_filter")
workflow.add_edge("metadata_filter", "expand_query")
```

#### 3.2.8 Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ `scripts/test_filtering.py`
**Ð”Ð»Ñ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:**
- Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ question Ð² dataset:
  - Run Ñ filtering: Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
  - Run Ð±ÐµÐ· filtering: Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
  - Ð¡Ñ€Ð°Ð²Ð½Ð¸Ñ‚ÑŒ recall, precision, latency
  - ÐŸÐ¾Ð´ÑÑ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ fallback rate
- Ð’Ñ‹Ð²ÐµÑÑ‚Ð¸: "Filtering ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ð» recall Ð½Ð° X%, fallback ÑÑ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Y% Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"

---

### Ð—ÐÐ”ÐÐ§Ð 3.3: Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Routing Logic
**Ð’Ñ€ÐµÐ¼Ñ:** 1 Ð´ÐµÐ½ÑŒ | **ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚:** ðŸŸ¡ MEDIUM

#### 3.3.1 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/nodes/routing/logic.py`
**ÐŸÐµÑ€ÐµÐ¿Ð¸ÑÐ°Ñ‚ÑŒ decide_action:**
```python
def decide_action(
    generation_confidence: float,     # avg(faithfulness, relevancy)
    faithfulness_score: float,        # Grounded in context?
    intent_confidence: float,         # Classification confidence
    fallback_triggered: bool,         # Metadata filter fallback?
    threshold_auto_reply: float = 0.85,
    threshold_needs_review: float = 0.5
) -> Literal["auto_reply", "needs_review", "escalation"]:
    """
    Smart routing based on multiple confidence metrics
    """

    # If we had to fallback filtering - be very cautious
    if fallback_triggered:
        if generation_confidence > threshold_auto_reply:
            return "needs_review"  # Don't auto-reply if fallback
        else:
            return "escalation"

    # Normal routing based on generation quality
    if generation_confidence > threshold_auto_reply and faithfulness_score > 0.8:
        return "auto_reply"

    elif generation_confidence > threshold_needs_review:
        return "needs_review"

    else:
        return "escalation"
```

#### 3.3.2 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/nodes/routing/node.py`
**Ð’Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ generation_confidence:**
```python
@observe(as_type="span")
async def route_node(state: Dict[str, Any]):
    """
    Improved routing node with multiple confidence metrics
    """
    faithfulness = state.get("faithfulness_score", 0.0)
    relevancy = state.get("relevancy_score", 0.0)
    intent_confidence = state.get("intent_confidence", 0.0)
    fallback_triggered = state.get("fallback_triggered", False)

    # Compute generation confidence as average
    generation_confidence = (faithfulness + relevancy) / 2

    action = decide_action(
        generation_confidence=generation_confidence,
        faithfulness_score=faithfulness,
        intent_confidence=intent_confidence,
        fallback_triggered=fallback_triggered
    )

    return {
        "action": action,
        "generation_confidence": generation_confidence,
        "faithfulness_score": faithfulness,
        "relevancy_score": relevancy
    }
```

#### 3.3.3 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/pipeline/state.py`
**Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð»Ñ:**
```python
class State(TypedDict):
    # ... existing fields ...

    # NEW: Confidence scores
    generation_confidence: Optional[float]   # avg(faithfulness, relevancy)
    faithfulness_score: Optional[float]
    relevancy_score: Optional[float]
```

#### 3.3.4 ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ `app/api/routes.py`
**Ð Ð°ÑÑˆÐ¸Ñ€Ð¸Ñ‚ÑŒ `/ask` response:**
```python
@router.get("/ask")
@observe()
async def ask(q: str = Query(...)):
    result = await rag_graph.ainvoke({"question": q})

    return {
        "question": q,
        "answer": result.get("answer"),
        "action": result.get("action"),

        # NEW: Detailed scores
        "scores": {
            "intent_confidence": result.get("intent_confidence"),
            "category_confidence": result.get("category_confidence"),
            "generation_confidence": result.get("generation_confidence"),
            "faithfulness": result.get("faithfulness_score"),
            "relevancy": result.get("relevancy_score"),
        },

        # NEW: Filter info
        "filter_stats": {
            "filter_used": result.get("filter_used"),
            "fallback_triggered": result.get("fallback_triggered"),
            "reason": result.get("filtering_reason"),
        },

        # Existing
        "context": result.get("docs"),
        "matched_intent": result.get("intent"),
        "matched_category": result.get("category"),
    }
```

---

## ðŸ“Š TIMELINE & DEPENDENCIES

```
DAY 1-2: Task 3.1 (Classification)
  â”œâ”€ 3.1.1-3.1.9: Implement classifier + test
  â””â”€ Update State & Graph

DAY 2-3: Task 3.2 (Metadata Filtering)
  â”œâ”€ 3.2.1-3.2.8: Implement filtering + test
  â”œâ”€ Update storage layer
  â””â”€ Integration with graph

DAY 4: Task 3.3 (Routing Logic)
  â”œâ”€ 3.3.1-3.3.4: Improve routing
  â”œâ”€ Update API response
  â””â”€ Integration testing

Total: ~4 days (can be done in parallel)
```

---

## ðŸ”„ UPDATED GRAPH FLOW

```
START
  â†“
[classify_node] â†’ intent, category, confidence
  â†“
[metadata_filter_node] â†’ filtered docs, fallback info
  â†“
[expand_query_node] â†’ query variants
  â†“
[hybrid_search_node] â†’ vector + lexical search
  â†“
[rerank_node] â†’ reranked docs
  â†“
[generate_node] â†’ answer + metrics
  â†“
[route_node] â†’ routing decision (auto_reply, needs_review, escalation)
  â†“
CONDITION:
â”œâ”€ auto_reply â†’ END
â”œâ”€ needs_review â†’ END (marked for review)
â””â”€ escalation â†’ END (marked for escalation)
```

---

## âœ… DEFINITION OF DONE

- âœ… Classification Node implemented (zero-shot BERT)
- âœ… Metadata Filtering with safety mechanisms
- âœ… Improved Routing Logic with multi-metric decision
- âœ… State updated with all new fields
- âœ… Graph updated with new nodes
- âœ… Storage layer supports category filtering
- âœ… API response includes all scores and stats
- âœ… All nodes logging to Langfuse
- âœ… Tests pass (classification, filtering, routing)
- âœ… Documentation updated
- âœ… Ready for next phase

---

## ðŸ“¦ DEPENDENCIES TO ADD TO requirements.txt

```
# Classification
transformers>=4.30.0
torch>=2.0.0  # or use pytorch-cpu for lightweight

# Everything else should already be there
```

---

## ðŸš€ NEXT PHASES (After Phase 3)

### Phase 4: Advanced Features (optional)
- 4.1 Multi-Hop Reasoning
- 4.2 Conversation Memory
- 4.3 Feedback Loop Integration

### Phase 5: Production Hardening
- 5.1 Error handling & retry logic
- 5.2 Caching strategies (Redis)
- 5.3 Rate limiting
- 5.4 Performance optimization

---

## ðŸ“ NOTES FOR IMPLEMENTATION

1. **Zero-shot BERT Details:**
   - Model: `facebook/bart-large-mnli` (~1.6GB)
   - Inference: ~150-200ms per question
   - Can be optimized with quantization if needed
   - Device: Auto-detect GPU, fallback to CPU

2. **Safety First:**
   - Always log filtering decisions
   - Monitor fallback rate weekly
   - If fallback > 30%, need to retrain classifier
   - Add alerts for classification failures

3. **Caching Strategy:**
   - Cache classification results (per question)
   - Use simple LRU cache initially
   - Consider Redis for distributed caching later

4. **Testing:**
   - Manual test with 10-20 questions
   - Automated test with full dataset
   - Compare metrics before/after Phase 3

5. **Documentation:**
   - Add example curl requests
   - Document confidence thresholds
   - Explain fallback behavior
