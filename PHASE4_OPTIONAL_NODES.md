# PHASE 4 - OPTIONAL ADVANCED RETRIEVAL NODES (ĞŸĞ»Ğ°Ğ½ Ğ±ĞµĞ· ĞºĞ¾Ğ´Ğ°)

Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑƒĞ·Ğ»Ñ‹ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ retrieval Ğ¿Ğ¾ÑĞ»Ğµ Ğ¤Ğ°Ğ·Ñ‹ 3.

---

## ğŸ¯ NODE 4.1: Multi-Hop Reasoning (Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹)

**Purpose:** Ğ”Ğ»Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ†ĞµĞ¿Ğ¾Ñ‡ĞºÑƒ ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ².

**Example:**
```
User: "ĞšĞ°Ğº Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ñ‚Ğ¾Ğ²Ğ°Ñ€, ĞµÑĞ»Ğ¸ Ğ¾Ğ½ Ğ±Ñ‹Ğ» Ğ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½ Ñ Ğ¿Ğ¾Ğ²Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸?"

Ğ‘ĞµĞ· Multi-Hop:
- Retrieve: "Return policy" Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚
- Generate: Ğ½ĞµĞ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ (Ğ½Ğµ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ process Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸)

Ğ¡ Multi-Hop:
- Retrieve: "Return policy" (1st doc)
  â†’ Find related: "Delivery process" (2nd doc)
  â†’ Find related: "Damage claims" (3rd doc)
- Generate: Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼ Ğ²ÑĞµÑ… 3 Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
```

**What to do:**

1. **Complexity Detection:**
   - ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ
   - ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸: ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ², Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°, Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ "Ğ¸", "ĞµÑĞ»Ğ¸", "Ğ¿Ğ¾ÑĞ»Ğµ"
   - Threshold: complexity_score > 0.6 â†’ use multi-hop

2. **Hop Logic:**
   - Step 1: Retrieve top-1 document Ğ´Ğ»Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°
   - Step 2: Extract keywords/entities Ğ¸Ğ· retrieved document
   - Step 3: Find related documents (Ñ‡ĞµÑ€ĞµĞ· metadata links Ğ¸Ğ»Ğ¸ semantic similarity)
   - Step 4: Combine Ğ²ÑĞµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ² Ğ¾Ğ´Ğ¸Ğ½ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ñ indication Ğ³Ğ´Ğµ ĞºĞ°ĞºĞ¾Ğ¹ doc)

3. **Implementation details:**
   - Create: `app/nodes/multihop/node.py`
   - Create: `app/nodes/multihop/complexity_detector.py` - Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ complexity_score
   - Create: `app/nodes/multihop/hop_resolver.py` - Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… docs
   - Update: `app/pipeline/state.py` - add `complexity_score`, `hops_used`
   - Update: `app/pipeline/graph.py` - conditional: if complexity_score > 0.6 â†’ use multihop

4. **Integration in graph:**
   ```
   ... â†’ retrieve â†’ [complexity_check] â†’
                        â”œâ”€ complex (>0.6) â†’ multihop â†’ merge_docs
                        â””â”€ simple (â‰¤0.6) â†’ skip
                                           â†“
                                         route â†’ ...
   ```

5. **Testing:**
   - Test on complex questions (with multiple entities)
   - Verify no infinite loops in hop resolution
   - Check latency doesn't increase too much

---

## ğŸ¯ NODE 4.2: Query Reformulation (Ğ£Ğ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ¸ÑĞº)

**Purpose:** ĞŸĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° (ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ domain-specific ÑĞ¸Ğ½Ğ¾Ğ½Ğ¸Ğ¼Ñ‹).

**Example:**
```
User: "Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°?"

Without Reformulation:
- Search: "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°" â†’ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğµ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ docs Ñ "shipping cost"

With Reformulation:
- Original: "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ°"
- Reformulations:
  1. "shipping cost"
  2. "delivery price"
  3. "shipping fee"
- Search by each variant â†’ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
```

**What to do:**

1. **Reformulation Strategy:**
   - Using LLM (gpt-4o-mini) to generate 2-3 reformulations
   - Include synonyms specific to domain (billing, shipping, etc.)
   - Reformulations should be shorter, more keyword-focused

2. **Implementation:**
   - Create: `app/nodes/query_reformulation/node.py`
   - Create: `app/nodes/query_reformulation/reformulator.py`
   - Prompt template: "Generate 2-3 alternative phrasings of this question, focusing on key terms used in technical documentation"

3. **Integration:**
   - Run AFTER classification (uses intent/category info for better reformulations)
   - Generate reformulations in parallel
   - Each reformulation searched separately
   - Combine results (deduplicate, merge scores)

4. **Update State:**
   - Add: `query_reformulations: List[str]`

5. **Update Graph:**
   ```
   classify â†’ metadata_filter â†’ [reformulate] â†’ retrieve (for each variant)
                                    â†“
                              [fusion] â†’ rerank
   ```

---

## ğŸ¯ NODE 4.3: Semantic Clustering (Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²)

**Purpose:** Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² Ğ¾Ğ´Ğ¸Ğ½ ĞºĞ»Ğ°ÑÑ‚ĞµÑ€ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°.

**Example:**
```
Without Clustering:
Retrieved docs:
1. "Return policy section 1"
2. "Return policy section 2"
3. "Shipping policy"

Result: 3 separate docs, some redundant

With Clustering:
Cluster 1 (Return Policy): docs 1, 2
Cluster 2 (Shipping): doc 3

Result: organized, easier for generation, less redundancy
```

**What to do:**

1. **Clustering Algorithm:**
   - Use embedding similarity to cluster documents
   - Threshold for "similar": cosine_similarity > 0.7
   - Group documents by semantic similarity

2. **Implementation:**
   - Create: `app/nodes/clustering/node.py`
   - Create: `app/nodes/clustering/clusterer.py` - clustering logic
   - Use: sklearn.cluster.AgglomerativeClustering or simple threshold-based grouping

3. **Output:**
   - Return clustered docs with cluster_id
   - Top doc from each cluster prioritized
   - Information about cluster cohesion (for logging)

4. **Integration:**
   ```
   ... â†’ rerank â†’ [clustering] â†’ generate
   ```
   - After reranking (so best docs are from best clusters)
   - Pass cluster info to generation for better context organization

5. **Benefits:**
   - Reduces redundancy in context
   - Better organization for generation
   - Can help with long contexts (select 1 doc per cluster)

---

## ğŸ¯ NODE 4.4: Cross-Reference Resolution (Ğ¡Ğ²ÑĞ·Ğ¸ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸)

**Purpose:** ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ğ½Ğ° ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑÑÑ‹Ğ»Ğ°ÑÑ‚ÑÑ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ (Ñ‡ĞµÑ€ĞµĞ· metadata links).

**Example:**
```
Retrieved doc: "FAQ - Return Process"
  metadata.see_also: ["Return Policy", "Shipping", "Damage Claims"]

Action:
- Retrieve linked documents
- Add to context with note: "(related: Return Policy)"
- Helps generate more complete answers
```

**What to do:**

1. **Link Extraction:**
   - Parse metadata.see_also, metadata.related_topics, etc.
   - Can be array of doc_ids or doc_titles

2. **Link Resolution:**
   - For each link: retrieve linked document
   - Limit to 1-2 links per doc (avoid explosion)
   - Check for circular references

3. **Implementation:**
   - Create: `app/nodes/cross_reference/node.py`
   - Create: `app/nodes/cross_reference/link_resolver.py`
   - Update: documents schema to include `see_also: List[str]` in metadata

4. **Integration:**
   ```
   ... â†’ rerank â†’ [cross_reference] â†’ generate
   ```
   - After reranking (limit links from top-k docs only)
   - Mark linked docs differently in context

5. **Data requirement:**
   - Documents need metadata.see_also populated during ingestion
   - Can be created manually or extracted from original documentation

---

## ğŸ“Š SUMMARY: Which nodes to implement?

| Node | Complexity | Impact | Priority | Estimated Time |
|------|-----------|--------|----------|-----------------|
| Multi-Hop | High | Medium | ğŸŸ¡ Medium | 2-3 days |
| Query Reformulation | Medium | High | ğŸŸ¡ Medium | 1-2 days |
| Semantic Clustering | Low | Low | ğŸŸ¢ Low | 1 day |
| Cross-Reference | Low | Medium | ğŸŸ¢ Low | 1 day |

**Recommendation:**
1. Start with **Query Reformulation** (high impact, medium effort)
2. Then **Multi-Hop Reasoning** (complex questions need this)
3. Optional: **Cross-Reference** (if metadata available)
4. Optional: **Semantic Clustering** (nice-to-have for UX)

---

## ğŸ”„ UPDATED GRAPH WITH ALL NODES (Phase 3 + Phase 4)

```
START
  â†“
[classify] â†’ intent, category
  â†“
[metadata_filter] â†’ filtered docs (with fallback)
  â†“
[reformulate] (Phase 4) â†’ multiple query variants
  â†“
[retrieve] â†’ retrieve for each variant (parallel)
  â†“
[fusion] â†’ combine results
  â†“
[rerank] â†’ cross-encoder reranking
  â†“
[clustering] (Phase 4) â†’ group similar docs
  â†“
[cross_reference] (Phase 4) â†’ resolve linked docs
  â†“
[multihop] (Phase 4, conditional) â†’ find related docs if complex
  â†“
[merge_context] â†’ combine all docs into final context
  â†“
[generate] â†’ LLM generation with full context
  â†“
[route] â†’ decision based on scores
  â†“
CONDITION:
â”œâ”€ auto_reply â†’ END
â”œâ”€ needs_review â†’ END
â””â”€ escalation â†’ END
```

---

## â±ï¸ Timeline Estimate

**Phase 3:** ~4 days (Done âœ…)
**Phase 4 Optional:**
- Query Reformulation: 1-2 days
- Multi-Hop Reasoning: 2-3 days
- Cross-Reference: 1 day
- Clustering: 1 day
- **Total Phase 4:** 5-7 days (or selective: pick 1-2 nodes)

**Total project:** Phase 1-3 (~1 week) + Phase 4 optional (~1 week) = **2-3 weeks for full MVP**

---

## âœ… What success looks like after Phase 4

**Before Phase 3:**
- Vector search only
- Simple confidence routing
- Low precision/recall

**After Phase 3:**
- Classification-aware retrieval
- Safety fallback for filtering
- Multi-metric routing
- ~30-40% improvement in retrieval quality

**After Phase 4 (if implemented):**
- Handle complex, multi-hop questions
- Better query understanding (reformulation)
- Organized context (clustering)
- Cross-document references
- ~50-60% improvement over baseline
- Production-ready for most support queries
